from config import Config
from utils.tokenizer import DNACryptoTokenizer
from models.dna_crypto_model import DNACryptoModel
from training.trainer import DNATrainer
from training.dataset import generate_training_data
import os
import random

def main():
    print("ğŸ§¬" + "="*50 + "ğŸ§¬")
    print("   DNA ENCRYPTION LLM TRAINING WITH GRAPHS")
    print("ğŸ§¬" + "="*50 + "ğŸ§¬")
    print()
    
    # Initialize configuration (auto-detects hardware)
    config = Config('auto')  # or specify 'minimal', 'standard', 'large'
    print(f"ğŸ“Š Configuration selected: {config.config_type.upper()}")
    print(f"ğŸ’» Device: {config.device}")
    print(f"ğŸ§  Estimated model size: {config._estimate_params():.1f}M parameters")
    print()
    
    # Create directories
    os.makedirs('saved_models', exist_ok=True)
    
    # Initialize tokenizer
    print("1ï¸âƒ£ Initializing tokenizer...")
    tokenizer = DNACryptoTokenizer()
    print(f"   ğŸ“ Text vocabulary: {tokenizer.text_vocab_size}")
    print(f"   ğŸ§¬ DNA vocabulary: {tokenizer.dna_vocab_size}")
    
    # Initialize model
    print("\n2ï¸âƒ£ Initializing DNA Crypto model...")
    model = DNACryptoModel(
        text_vocab_size=tokenizer.text_vocab_size,
        dna_vocab_size=tokenizer.dna_vocab_size,
        **config.model_config
    )
    
    total_params = sum(p.numel() for p in model.parameters())
    print(f"   ğŸ¯ Total parameters: {total_params:,} ({total_params/1e6:.1f}M)")
    
    # Generate training data with train/validation split
    print("\n3ï¸âƒ£ Generating training data...")
    all_texts = generate_training_data(config.training_config['num_samples'])
    
    # Split into train/validation (80/20) - Like in research papers
    random.shuffle(all_texts)
    split_idx = int(0.8 * len(all_texts))
    train_texts = all_texts[:split_idx]
    val_texts = all_texts[split_idx:]
    
    print(f"   ğŸ“š Training samples: {len(train_texts)}")
    print(f"   âœ… Validation samples: {len(val_texts)}")
    
    # Initialize enhanced trainer with graphing capabilities
    print("\n4ï¸âƒ£ Initializing enhanced trainer...")
    trainer = DNATrainer(model, tokenizer, config)
    
    # Start training with comprehensive metrics collection
    print("\n5ï¸âƒ£ Starting training with graph generation...")
    print(f"   ğŸ“ˆ Epochs: {config.training_config['epochs']}")
    print(f"   ğŸ“¦ Batch size: {config.training_config['batch_size']}")
    print(f"   ğŸ¯ Learning rate: {config.training_config['learning_rate']}")
    print(f"   ğŸ“Š Metrics: Loss, Accuracy, Training Time")
    print("   ğŸ¨ Graphs: Will be generated after training")
    print("="*70)
    
    try:
        # Start training with validation
        trainer.train(train_texts, val_texts)
        
        print("\nğŸ‰ SUCCESS! Training completed!")
        print("ğŸ“Š Check 'saved_models/training_curves.png' for your graphs!")
        print("ğŸ’¾ Training data saved in 'training_history.json'")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ Training interrupted by user")
        trainer.save_checkpoint("saved_models/interrupted_checkpoint.pth")
        trainer.plot_comprehensive_training_curves()
        print("ğŸ“Š Partial training graphs generated!")
        
    except Exception as e:
        print(f"\nâŒ Training failed: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
